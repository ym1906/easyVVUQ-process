{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infeasibility UQ\n",
    "\n",
    "Take the generic DEMO solution, turned into an input file. Remove f-values at iteration vars, and replace their equality constraints with inequalities. Run PROCESS once-through with uncertain inputs, and the QoI as the value of constraints, i.e. the infeasibility.\n",
    "\n",
    "Dask is used to parallelise the evaluations for a SLURM cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T16:59:41.649134Z",
     "iopub.status.busy": "2024-01-12T16:59:41.648824Z",
     "iopub.status.idle": "2024-01-12T16:59:50.090648Z",
     "shell.execute_reply": "2024-01-12T16:59:50.089917Z"
    }
   },
   "outputs": [],
   "source": [
    "import easyvvuq as uq\n",
    "import chaospy as cp\n",
    "from pathlib import Path\n",
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Campaign to capture feasibility\n",
    "\n",
    "Using the epistemic uncertain inputs for the entire code, capture the distribution of constraint residuals.\n",
    "\n",
    "To start with, make just 4 inputs uncertain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T16:59:50.094923Z",
     "iopub.status.busy": "2024-01-12T16:59:50.094643Z",
     "iopub.status.idle": "2024-01-12T17:04:02.978013Z",
     "shell.execute_reply": "2024-01-12T17:04:02.977114Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/graeme/process/env/lib/python3.10/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 33315 instead\n",
      "  warnings.warn(\n",
      "ERROR:tornado.application:Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x7ff991955180>>, <Task finished name='Task-17' coro=<SpecCluster._correct_state_internal() done, defined at /home/graeme/process/env/lib/python3.10/site-packages/distributed/deploy/spec.py:346> exception=FileNotFoundError(2, 'No such file or directory')>)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/graeme/process/env/lib/python3.10/site-packages/tornado/ioloop.py\", line 740, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/home/graeme/process/env/lib/python3.10/site-packages/tornado/ioloop.py\", line 764, in _discard_future_result\n",
      "    future.result()\n",
      "  File \"/home/graeme/process/env/lib/python3.10/site-packages/distributed/deploy/spec.py\", line 390, in _correct_state_internal\n",
      "    await asyncio.gather(*worker_futs)\n",
      "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 650, in _wrap_awaitable\n",
      "    return (yield from awaitable.__await__())\n",
      "  File \"/home/graeme/process/env/lib/python3.10/site-packages/distributed/deploy/spec.py\", line 74, in _\n",
      "    await self.start()\n",
      "  File \"/home/graeme/process/env/lib/python3.10/site-packages/dask_jobqueue/core.py\", line 411, in start\n",
      "    out = await self._submit_job(fn)\n",
      "  File \"/home/graeme/process/env/lib/python3.10/site-packages/dask_jobqueue/core.py\", line 394, in _submit_job\n",
      "    return self._call(shlex.split(self.submit_command) + [script_filename])\n",
      "  File \"/home/graeme/process/env/lib/python3.10/site-packages/dask_jobqueue/core.py\", line 481, in _call\n",
      "    proc = subprocess.Popen(\n",
      "  File \"/usr/lib/python3.10/subprocess.py\", line 971, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"/usr/lib/python3.10/subprocess.py\", line 1863, in _execute_child\n",
      "    raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'sbatch'\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "start-993cc200a26ff26b386b103fb1c24dde",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 124\u001b[0m\n\u001b[1;32m    121\u001b[0m campaign\u001b[38;5;241m.\u001b[39mset_sampler(pce_sampler)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Draw samples, execute and collate\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m \u001b[43mcampaign\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m samples \u001b[38;5;241m=\u001b[39m campaign\u001b[38;5;241m.\u001b[39mget_collation_result()\n\u001b[1;32m    126\u001b[0m samples\n",
      "File \u001b[0;32m~/process/env/lib/python3.10/site-packages/easyvvuq/actions/action_statuses.py:138\u001b[0m, in \u001b[0;36mActionPool.collate\u001b[0;34m(self, progress_bar)\u001b[0m\n\u001b[1;32m    136\u001b[0m     tqdm_ \u001b[38;5;241m=\u001b[39m tqdm\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool, Client):\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequential \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool, Client):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m tqdm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults)):\n",
      "File \u001b[0;32m~/process/env/lib/python3.10/site-packages/distributed/client.py:2383\u001b[0m, in \u001b[0;36mClient.gather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   2380\u001b[0m     local_worker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2382\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m-> 2383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2384\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gather\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2386\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2389\u001b[0m \u001b[43m        \u001b[49m\u001b[43masynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2390\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/process/env/lib/python3.10/site-packages/distributed/client.py:2244\u001b[0m, in \u001b[0;36mClient._gather\u001b[0;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[1;32m   2242\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2243\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exception\u001b[38;5;241m.\u001b[39mwith_traceback(traceback)\n\u001b[0;32m-> 2244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   2245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2246\u001b[0m     bad_keys\u001b[38;5;241m.\u001b[39madd(key)\n",
      "\u001b[0;31mCancelledError\u001b[0m: start-993cc200a26ff26b386b103fb1c24dde"
     ]
    }
   ],
   "source": [
    "# Init cluster (describes a single node, or less if need less than that per worker)\n",
    "# cluster = SLURMCluster(\n",
    "#     cores=56,\n",
    "#     processes=4,  # check docs\n",
    "#     memory=\"192GB\",\n",
    "#     account=\"UKAEA-AP002-CPU\",\n",
    "#     walltime=\"01:00:00\",\n",
    "#     queue=\"cclake\",\n",
    "# )\n",
    "\n",
    "# Need less than a full node per worker\n",
    "cluster = SLURMCluster(\n",
    "    cores=1,\n",
    "    processes=1,\n",
    "    memory=\"4GB\",\n",
    "    account=\"UKAEA-AP002-CPU\",\n",
    "    walltime=\"00:05:00\",\n",
    "    queue=\"cclake\",\n",
    ")\n",
    "cluster.scale(4)  # 4 workers\n",
    "# print(cluster.job_script())\n",
    "\n",
    "# Connect Dask client to remote cluster\n",
    "client = Client(cluster)\n",
    "# Code from now on submitted to batch queue\n",
    "\n",
    "# Define campaign\n",
    "WORK_DIR = \"campaigns\"\n",
    "Path(\"campaigns\").mkdir(exist_ok=True)\n",
    "campaign = uq.Campaign(name=\"example_cluster\", work_dir=WORK_DIR)\n",
    "\n",
    "# Define parameter space\n",
    "# Uncertainties from Alex's SA paper\n",
    "\n",
    "params = {\n",
    "    \"fdene\": {\n",
    "        \"type\": \"float\",\n",
    "        \"min\": 1.1,\n",
    "        \"max\": 1.3,\n",
    "        \"default\": 1.2,\n",
    "    },  # check: not sure if this is right var. I think ok\n",
    "    \"hfact\": {\"type\": \"float\", \"min\": 1.0, \"max\": 1.2, \"default\": 1.2},\n",
    "    \"coreradius\": {\"type\": \"float\", \"min\": 0.45, \"max\": 0.75, \"default\": 0.75},  # ok\n",
    "    \"fimp_2\": {\"type\": \"float\", \"min\": 0.085, \"max\": 0.115, \"default\": 0.1},  # ok\n",
    "    \"fimp_14\": {\n",
    "        \"type\": \"float\",\n",
    "        \"min\": 1.0e-5,\n",
    "        \"max\": 1.0e-4,\n",
    "        \"default\": 1.0e-5,\n",
    "    },  # ok\n",
    "    \"psepbqarmax\": {\"type\": \"float\", \"min\": 8.7, \"max\": 9.7, \"default\": 9.0},  # ok\n",
    "    \"flhthresh\": {\"type\": \"float\", \"min\": 0.85, \"max\": 1.15, \"default\": 1.15},  # ok\n",
    "    \"cboot\": {\n",
    "        \"type\": \"float\",\n",
    "        \"min\": 0.95,\n",
    "        \"max\": 1.05,\n",
    "        \"default\": 1.0,\n",
    "    },  # ok\n",
    "    \"peakfactrad\": {\"type\": \"float\", \"min\": 2.0, \"max\": 3.5, \"default\": 3.33},  # ok\n",
    "    \"kappa\": {\"type\": \"float\", \"min\": 1.8, \"max\": 1.9, \"default\": 1.848},  # ok\n",
    "    \"etaech\": {\"type\": \"float\", \"min\": 0.3, \"max\": 0.5, \"default\": 0.4},  # ok\n",
    "    \"feffcd\": {\"type\": \"float\", \"min\": 0.5, \"max\": 5.0, \"default\": 1.0},  # ok\n",
    "    \"etath\": {\"type\": \"float\", \"min\": 0.36, \"max\": 0.4, \"default\": 0.375},  # ok\n",
    "    \"etaiso\": {\"type\": \"float\", \"min\": 0.75, \"max\": 0.95, \"default\": 0.9},  # ok\n",
    "    \"boundl_18\": {\n",
    "        \"type\": \"float\",\n",
    "        \"min\": 3.25,\n",
    "        \"max\": 3.75,\n",
    "        \"default\": 3.25,\n",
    "    },  # q^95_min, ok\n",
    "    \"pinjalw\": {\"type\": \"float\", \"min\": 51.0, \"max\": 61.0, \"default\": 61.0},  # ok\n",
    "    \"alstroh\": {\"type\": \"float\", \"min\": 6.0e8, \"max\": 7.2e8, \"default\": 6.6e8},  # ok\n",
    "    \"sig_tf_wp_max\": {\n",
    "        \"type\": \"float\",\n",
    "        \"min\": 5.2e8,\n",
    "        \"max\": 6.4e8,\n",
    "        \"default\": 6.4e8,\n",
    "    },  # ok, but might need sig_tf_case_max to be the same too\n",
    "    \"aspect\": {\"type\": \"float\", \"min\": 3.0, \"max\": 3.2, \"default\": 3.1},\n",
    "    \"boundu_2\": {\n",
    "        \"type\": \"float\",\n",
    "        \"min\": 11.0,\n",
    "        \"max\": 12.0,\n",
    "        \"default\": 12.0,\n",
    "    },  # B_T^max, ok\n",
    "    \"triang\": {\"type\": \"float\", \"min\": 0.4, \"max\": 0.6, \"default\": 0.5},  # ok\n",
    "    \"vary_param\": {\n",
    "        \"type\": \"string\",\n",
    "        \"default\": \"\",\n",
    "    },  # param being changed: used for analysis only\n",
    "}\n",
    "\n",
    "# QoIs\n",
    "# Violated constraint residuals\n",
    "qois = [\n",
    "    \"rms_vio_constr_res\",\n",
    "]\n",
    "\n",
    "# Create encoder and decoder\n",
    "encoder = uq.encoders.GenericEncoder(\n",
    "    template_fname=\"demo_sol_max_net_elec_no_f_IN.template\", target_filename=\"IN.DAT\"\n",
    ")\n",
    "decoder = uq.decoders.JSONDecoder(target_filename=\"responses.json\", output_columns=qois)\n",
    "\n",
    "cmd = \"process -i IN.DAT\"\n",
    "actions = uq.actions.local_execute(encoder, cmd, decoder)\n",
    "\n",
    "# Add the app\n",
    "campaign.add_app(name=\"feasibility\", params=params, actions=actions)\n",
    "\n",
    "# Create PCE sampler, 4 uncertainties\n",
    "vary = {\n",
    "    \"aspect\": cp.Uniform(3.0, 3.2),\n",
    "    \"triang\": cp.Uniform(0.4, 0.6),\n",
    "    \"psepbqarmax\": cp.Uniform(8.7, 9.7),\n",
    "    \"hfact\": cp.Uniform(1.0, 1.2),\n",
    "}\n",
    "pce_sampler = uq.sampling.PCESampler(vary=vary, polynomial_order=3)\n",
    "\n",
    "# Add pce_sampler to campaign\n",
    "campaign.set_sampler(pce_sampler)\n",
    "\n",
    "# Draw samples, execute and collate\n",
    "campaign.execute(pool=client).collate(progress_bar=True)\n",
    "samples = campaign.get_collation_result()\n",
    "samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
